import torch.nn.functional
from rlpyt.models.conv2d import Conv2dModel as Conv2dModel
from rlpyt.models.mlp import MlpModel as MlpModel
from rlpyt.models.running_mean_std import RunningMeanStdModel as RunningMeanStdModel
from rlpyt.utils.logging import logger as logger
from rlpyt.utils.tensor import infer_leading_dims as infer_leading_dims, restore_leading_dims as restore_leading_dims
from typing import Any, Optional

def weight_init(m: Any) -> None: ...

class AtariPgModel(torch.nn.Module):
    conv: Any = ...
    pi_v_mlp: Any = ...
    stop_conv_grad: Any = ...
    conv_rms: Any = ...
    var_clip: float = ...
    normalize_conv_out: Any = ...
    def __init__(self, image_shape: Any, action_size: Any, hidden_sizes: int = ..., stop_conv_grad: bool = ..., channels: Optional[Any] = ..., kernel_sizes: Optional[Any] = ..., strides: Optional[Any] = ..., paddings: Optional[Any] = ..., kiaming_init: bool = ..., normalize_conv_out: bool = ...) -> None: ...
    def forward(self, observation: Any, prev_action: Any, prev_reward: Any): ...
    def update_conv_rms(self, observation: Any) -> None: ...
    def parameters(self) -> None: ...
    def named_parameters(self) -> None: ...
    @property
    def conv_out_size(self): ...

class AtariDqnModel(torch.nn.Module):
    conv: Any = ...
    q_mlp: Any = ...
    stop_conv_grad: Any = ...
    conv_rms: Any = ...
    var_clip: float = ...
    normalize_conv_out: Any = ...
    def __init__(self, image_shape: Any, action_size: Any, hidden_sizes: int = ..., stop_conv_grad: bool = ..., channels: Optional[Any] = ..., kernel_sizes: Optional[Any] = ..., strides: Optional[Any] = ..., paddings: Optional[Any] = ..., kiaming_init: bool = ..., normalize_conv_out: bool = ...) -> None: ...
    def forward(self, observation: Any, prev_action: Any, prev_reward: Any): ...
    def update_conv_rms(self, observation: Any) -> None: ...
    def parameters(self) -> None: ...
    def named_parameters(self) -> None: ...
    @property
    def conv_out_size(self): ...
