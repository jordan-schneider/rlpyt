import torch
from rlpyt.models.conv2d import Conv2dModel as Conv2dModel
from rlpyt.models.mlp import MlpModel as MlpModel
from rlpyt.ul.models.dmlab_conv2d import DmlabConv2dModel as DmlabConv2dModel
from rlpyt.utils.tensor import infer_leading_dims as infer_leading_dims, restore_leading_dims as restore_leading_dims
from typing import Any, Optional

def weight_init(m: Any) -> None: ...

class EncoderModel(torch.nn.Module):
    conv: Any = ...
    head: Any = ...
    def __init__(self, image_shape: Any, latent_size: Any, channels: Any, kernel_sizes: Any, strides: Any, paddings: Optional[Any] = ..., hidden_sizes: Optional[Any] = ..., kiaming_init: bool = ...) -> None: ...
    def forward(self, observation: Any): ...
    @property
    def output_size(self): ...
    @property
    def output_shape(self): ...

class DmlabEncoderModel(torch.nn.Module):
    conv: Any = ...
    head: Any = ...
    def __init__(self, image_shape: Any, latent_size: Any, use_fourth_layer: bool = ..., skip_connections: bool = ..., hidden_sizes: Optional[Any] = ..., kiaming_init: bool = ...) -> None: ...
    def forward(self, observation: Any): ...
    @property
    def output_size(self): ...
    @property
    def output_shape(self): ...
