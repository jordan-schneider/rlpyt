import torch.nn.functional
from rlpyt.models.mlp import MlpModel as MlpModel
from rlpyt.models.utils import conv2d_output_shape as conv2d_output_shape
from rlpyt.utils.tensor import infer_leading_dims as infer_leading_dims, restore_leading_dims as restore_leading_dims
from typing import Any, Optional

def weight_init(m: Any) -> None: ...

class StDimEncoderModel(torch.nn.Module):
    conv: Any = ...
    head: Any = ...
    def __init__(self, image_shape: Any, latent_size: Any, channels: Optional[Any] = ..., kernel_sizes: Optional[Any] = ..., strides: Optional[Any] = ..., paddings: Optional[Any] = ..., hidden_sizes: Optional[Any] = ..., kiaming_init: bool = ...) -> None: ...
    def forward(self, observation: Any): ...
    @property
    def conv_layer_shapes(self): ...
    @property
    def conv_out_shapes(self): ...
    @property
    def output_size(self): ...
    @property
    def output_shape(self): ...

class StDimGlobalLocalContrastModel(torch.nn.Module):
    anchor_mlp: Any = ...
    W: Any = ...
    def __init__(self, latent_size: Any, local_size: Any, anchor_hidden_sizes: Any) -> None: ...
    def forward(self, anchor: Any, positive: Any): ...

class StDimLocalLocalContrastModel(torch.nn.Module):
    anchor_mlp: Any = ...
    W: Any = ...
    def __init__(self, local_size: Any, anchor_hidden_sizes: Any) -> None: ...
    def forward(self, anchor: Any, positive: Any): ...

class Conv2dStdimModel(torch.nn.Module):
    conv: Any = ...
    conv_layers: Any = ...
    maxp_layers: Any = ...
    def __init__(self, in_channels: Any, channels: Any, kernel_sizes: Any, strides: Any, paddings: Optional[Any] = ..., nonlinearity: Any = ..., use_maxpool: bool = ...) -> None: ...
    def forward(self, input: Any): ...
    def conv_out_size(self, h: Any, w: Any, c: Optional[Any] = ...): ...
    def conv_layer_shapes(self, h: Any, w: Any, c: Optional[Any] = ...): ...
    def conv_out_shape(self, h: Any, w: Any, c: Optional[Any] = ...): ...
    def conv_out_shapes(self, *args: Any, **kwargs: Any): ...
