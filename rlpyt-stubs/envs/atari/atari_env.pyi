from collections import namedtuple
from rlpyt.envs.base import Env as Env, EnvStep as EnvStep
from rlpyt.samplers.collections import TrajInfo as TrajInfo
from rlpyt.spaces.int_box import IntBox as IntBox
from rlpyt.utils.quick_args import save__init__args as save__init__args
from typing import Any

W: Any
H: Any

EnvInfo = namedtuple('EnvInfo', ['game_score', 'traj_done'])

class AtariTrajInfo(TrajInfo):
    GameScore: int = ...
    def __init__(self, **kwargs: Any) -> None: ...
    def step(self, observation: Any, action: Any, reward: Any, done: Any, agent_info: Any, env_info: Any) -> None: ...

class AtariEnv(Env):
    ale: Any = ...
    def __init__(self, game: str = ..., frame_skip: int = ..., num_img_obs: int = ..., clip_reward: bool = ..., episodic_lives: bool = ..., fire_on_reset: bool = ..., max_start_noops: int = ..., repeat_action_probability: float = ..., horizon: int = ...) -> None: ...
    def reset(self): ...
    def step(self, action: Any): ...
    def render(self, wait: int = ..., show_full_obs: bool = ...) -> None: ...
    def get_obs(self): ...
    def fire_and_up(self) -> None: ...
    @property
    def game(self): ...
    @property
    def frame_skip(self): ...
    @property
    def num_img_obs(self): ...
    @property
    def clip_reward(self): ...
    @property
    def max_start_noops(self): ...
    @property
    def episodic_lives(self): ...
    @property
    def repeat_action_probability(self): ...
    @property
    def horizon(self): ...
    def get_action_meanings(self): ...

ACTION_MEANING: Any
ACTION_INDEX: Any
