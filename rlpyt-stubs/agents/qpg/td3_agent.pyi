# Stubs for rlpyt.agents.qpg.td3_agent (Python 3)
#
# NOTE: This dynamically typed stub was automatically generated by stubgen.

from rlpyt.agents.qpg.ddpg_agent import DdpgAgent
from typing import Any, Optional

class Td3Agent(DdpgAgent):
    min_itr_learn: int = ...
    def __init__(self, pretrain_std: float = ..., target_noise_std: float = ..., target_noise_clip: float = ..., initial_q2_model_state_dict: Optional[Any] = ..., **kwargs: Any) -> None: ...
    q2_model: Any = ...
    target_q2_model: Any = ...
    target_distribution: Any = ...
    def initialize(self, env_spaces: Any, share_memory: bool = ..., global_B: int = ..., env_ranks: Optional[Any] = ...) -> None: ...
    def to_device(self, cuda_idx: Optional[Any] = ...) -> None: ...
    def data_parallel(self) -> None: ...
    def give_min_itr_learn(self, min_itr_learn: Any) -> None: ...
    def q(self, observation: Any, prev_action: Any, prev_reward: Any, action: Any): ...
    def target_q_at_mu(self, observation: Any, prev_action: Any, prev_reward: Any): ...
    def update_target(self, tau: int = ...) -> None: ...
    def q_parameters(self) -> None: ...
    def set_target_noise(self, std: Any, noise_clip: Optional[Any] = ...) -> None: ...
    def train_mode(self, itr: Any) -> None: ...
    def sample_mode(self, itr: Any) -> None: ...
    def eval_mode(self, itr: Any) -> None: ...
    def state_dict(self): ...
    def load_state_dict(self, state_dict: Any) -> None: ...
